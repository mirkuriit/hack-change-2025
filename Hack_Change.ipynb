{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"b953d757480041909bd66a0f04d8ca25":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2577e7494d1a4c8d8ba4c09ee6259eda","IPY_MODEL_d68c14c337984ba79a4413e800ad842c","IPY_MODEL_2a18a70434ca45d295de27f715b28cb2"],"layout":"IPY_MODEL_df6aa764480048449a3bf9960cbec9b6"}},"2577e7494d1a4c8d8ba4c09ee6259eda":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a26053054d424f25a48fc60bbff76f71","placeholder":"‚Äã","style":"IPY_MODEL_1b9fbcdb017b4136a7df52aa1c6afebc","value":"Epoch‚Äá1/4:‚Äá100%"}},"d68c14c337984ba79a4413e800ad842c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_b64f1a4864fc439699986911911940c0","max":8366,"min":0,"orientation":"horizontal","style":"IPY_MODEL_601e2d75904e45a69820dff30d333f01","value":8366}},"2a18a70434ca45d295de27f715b28cb2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_477159f874d5433da593b7aa7e620eb8","placeholder":"‚Äã","style":"IPY_MODEL_bb585f852fc1402792a88cbeaa3ae71f","value":"‚Äá8365/8366‚Äá[04:58&lt;00:00,‚Äá28.48it/s]"}},"df6aa764480048449a3bf9960cbec9b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"a26053054d424f25a48fc60bbff76f71":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b9fbcdb017b4136a7df52aa1c6afebc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b64f1a4864fc439699986911911940c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"601e2d75904e45a69820dff30d333f01":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"477159f874d5433da593b7aa7e620eb8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb585f852fc1402792a88cbeaa3ae71f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"13b9cf4d9cc64747be0865885d932ec8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f21a9d1849ff491f8bb09a36ff026242","IPY_MODEL_2761b478036c4be7899ddd5150de85a6","IPY_MODEL_f06c0dcce50f4a9f93178ca3afe74ca7"],"layout":"IPY_MODEL_1ecac6921562442597aacd876c4b3a51"}},"f21a9d1849ff491f8bb09a36ff026242":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d09fba8345f4b05a30bfa7b73f2a1f7","placeholder":"‚Äã","style":"IPY_MODEL_eaeda769480c4342935664c6900294ea","value":"Epoch‚Äá2/4:‚Äá‚Äá56%"}},"2761b478036c4be7899ddd5150de85a6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b68da0cfced47febd6650ae9f348b74","max":8366,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dba3e15f128d4926928d241f7e9511a5","value":4717}},"f06c0dcce50f4a9f93178ca3afe74ca7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c612edb59b74a7ab49f9430cf69dbb3","placeholder":"‚Äã","style":"IPY_MODEL_b46a61bdf9cd40368b947c0957f39264","value":"‚Äá4717/8366‚Äá[02:48&lt;02:06,‚Äá28.81it/s]"}},"1ecac6921562442597aacd876c4b3a51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d09fba8345f4b05a30bfa7b73f2a1f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eaeda769480c4342935664c6900294ea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3b68da0cfced47febd6650ae9f348b74":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dba3e15f128d4926928d241f7e9511a5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5c612edb59b74a7ab49f9430cf69dbb3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b46a61bdf9cd40368b947c0957f39264":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://dmiptrv0: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@github.com/mirkuriit/hack-change-2025.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T12:56:31.477433Z","iopub.execute_input":"2025-11-29T12:56:31.477788Z","iopub.status.idle":"2025-11-29T12:56:32.430549Z","shell.execute_reply.started":"2025-11-29T12:56:31.477756Z","shell.execute_reply":"2025-11-29T12:56:32.429414Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'hack-change-2025'...\nremote: Enumerating objects: 89, done.\u001b[K\nremote: Counting objects: 100% (89/89), done.\u001b[K\nremote: Compressing objects: 100% (66/66), done.\u001b[K\nremote: Total 89 (delta 21), reused 77 (delta 14), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (89/89), 71.35 KiB | 4.46 MiB/s, done.\nResolving deltas: 100% (21/21), done.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import shutil\n\nsource_path = '/kaggle/working/hack-change-2025/Hack_Change.ipynb'\nworking_path = '/kaggle/working/Hack_Change.ipynb'\n\nshutil.copy(source_path, working_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T13:03:37.858481Z","iopub.execute_input":"2025-11-29T13:03:37.858774Z","iopub.status.idle":"2025-11-29T13:03:37.866139Z","shell.execute_reply.started":"2025-11-29T13:03:37.858754Z","shell.execute_reply":"2025-11-29T13:03:37.865024Z"}},"outputs":[{"name":"stdout","text":"üìù –ù–æ—É—Ç–±—É–∫ —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω: /kaggle/working/Hack_Change.ipynb\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"from google.colab import drive\ndrive.mount('/content/drive')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1297,"status":"ok","timestamp":1764414015317,"user":{"displayName":"–î–º–∏—Ç—Ä–∏–π –ü–µ—Ç—Ä–æ–≤","userId":"07403972255786892434"},"user_tz":-180},"id":"QUTAtSHaialn","outputId":"ba74f27b-505b-4dbd-f4a9-11e1869bd904"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"execution_count":14},{"cell_type":"code","source":"import numpy as np\nfrom torch.autograd import Variable\nfrom torchvision import datasets\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.utils.data as data_utils\nimport torch\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\nfrom numpy.linalg import norm\nfrom collections import Counter\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom torch.utils.data import Dataset, DataLoader\n\nimport os\nimport pandas as pd\nimport skimage.io\nfrom skimage.transform import resize\nimport re\nimport string\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\n\nimport pickle\n\nimport gdown\n%matplotlib inline\n\nBASE_DIR = \"/content/drive/MyDrive/Colab_data\"\nDATA_DIR = \"/content/Colab_Data\"\n\nnltk.download('punkt')\nnltk.download('punkt_tab')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9995,"status":"ok","timestamp":1764413924084,"user":{"displayName":"–î–º–∏—Ç—Ä–∏–π –ü–µ—Ç—Ä–æ–≤","userId":"07403972255786892434"},"user_tz":-180},"id":"O_hdAJ62x5ve","outputId":"afacdc91-4ece-4cbb-a99d-6edec62fc648"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}],"execution_count":3},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":32,"status":"ok","timestamp":1764413924135,"user":{"displayName":"–î–º–∏—Ç—Ä–∏–π –ü–µ—Ç—Ä–æ–≤","userId":"07403972255786892434"},"user_tz":-180},"id":"NJqbDq8E8RqJ","outputId":"ff9ffcf3-a8d6-45ee-b4fa-1611d168b0db"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cuda'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}],"execution_count":4},{"cell_type":"code","source":"# Simple tokenizer -> Rewrite\nclass MyTokenizer:\n    def __init__(self):\n        pass\n    def tokenize(self, text):\n        return [x.lower() for x in re.findall(r'\\w+', text)]\n\n    def encode(self, text):\n        tokens = [self.word2ind.get(word, self.word2ind['<unk>']) for word in self.tokenize(text)]\n        return tokens","metadata":{"id":"D5A7mmDu346j","executionInfo":{"status":"ok","timestamp":1764413924138,"user_tz":-180,"elapsed":1,"user":{"displayName":"–î–º–∏—Ç—Ä–∏–π –ü–µ—Ç—Ä–æ–≤","userId":"07403972255786892434"}}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"tokenizer = MyTokenizer()","metadata":{"id":"HZlZcx5s363U","executionInfo":{"status":"ok","timestamp":1764413924216,"user_tz":-180,"elapsed":70,"user":{"displayName":"–î–º–∏—Ç—Ä–∏–π –ü–µ—Ç—Ä–æ–≤","userId":"07403972255786892434"}}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"train_data = np.array(pd.read_csv(f\"{BASE_DIR}/Hack_Change/train.csv\"))\ntest_data = np.array(pd.read_csv(f\"{BASE_DIR}/Hack_Change/test.csv\"))","metadata":{"id":"gzpwlyXt5q2n","executionInfo":{"status":"ok","timestamp":1764414031544,"user_tz":-180,"elapsed":8578,"user":{"displayName":"–î–º–∏—Ç—Ä–∏–π –ü–µ—Ç—Ä–æ–≤","userId":"07403972255786892434"}}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def show_item(ind, data):\n  print(\"Id: \", data[ind][0])\n  print(\"Text: \", data[ind][1])\n  print(\"Source: \", data[ind][2])\n\n\nshow_item(1, train_data)\nprint(len(train_data))\nprint(len(test_data))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1764414035801,"user":{"displayName":"–î–º–∏—Ç—Ä–∏–π –ü–µ—Ç—Ä–æ–≤","userId":"07403972255786892434"},"user_tz":-180},"id":"5z3cDSd066lR","outputId":"2a0a79a3-726c-4715-d0e8-57e8da182606"},"outputs":[{"output_type":"stream","name":"stdout","text":["Id:  198426\n","Text:  –°–ª–µ–≤–∞ –æ—Ç –º–µ–Ω—è –ê–ª–µ–∫—Å–µ–π –ò–ª—å–º—É—Ö–∏–Ω. –ü—É—Ç–µ—à–µ—Å—Ç–≤–µ–Ω–Ω–∏–∫ –∏ –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π —á–µ–ª–æ–≤–µ–∫. –í —á–∏—Å–ª–µ –µ–≥–æ –ª–∏—á–Ω—ã—Ö –ø–æ–±–µ–¥ - –ø—É—Ç–µ—à–µ—Å—Ç–≤–∏–µ –Ω–∞ –≤–µ–ª–æ—Å–∏–ø–µ–¥–µ –æ—Ç –ß–µ–ª—è–±–∏–Ω—Å–∫–∞ –¥–æ –ë–∞–π–∫–∞–ª–∞... –ü—Ä–∏–µ—Ö–∞–ª –∫ –Ω–∞–º –ø–æ–º–æ—á—å –≤ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ —Å–µ–º–∏–Ω–∞—Ä–∞ –ú—É—Ö—Ç–∞—Ä–∞. –ü—Ä–æ—Å—Ç–æ –≤–∑—è–ª –∏ –ø—Ä–∏–µ—Ö–∞–ª –∏–∑ –ß–µ–ª—è–±–∏–Ω—Å–∫–∞ –∏ –Ω–∞—á–∞–ª –ø–æ–º–æ–≥–∞—Ç—å... ))üëç #–º–æ–∂–µ—Ç–∫–∞–∂–¥—ã–π\n","Source:  rusentiment\n","232366\n","58092\n"]}],"execution_count":17},{"cell_type":"code","source":"# print(pd.read_csv(f\"{BASE_DIR}/Hack&Change/train.csv\").head())","metadata":{"id":"rlcMDXnoRFRV","executionInfo":{"status":"ok","timestamp":1764414036118,"user_tz":-180,"elapsed":4,"user":{"displayName":"–î–º–∏—Ç—Ä–∏–π –ü–µ—Ç—Ä–æ–≤","userId":"07403972255786892434"}}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# Creating vocabulary\nwords = Counter()\n\nfor i in range(len(train_data)):\n  proccessed_text = train_data[i][1].lower().translate(str.maketrans('', '', string.punctuation))\n\n  for word in word_tokenize(proccessed_text):\n    words[word] += 1\n\nvocab = set(['<unk>', '<bos>', '<eos>', '<pad>'])\ncounter_threshold = 5\n\nfor char, cnt in words.items():\n    if cnt > counter_threshold:\n        vocab.add(char)\n\nprint(f'Vocabulary length: {len(vocab)}')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":82192,"status":"ok","timestamp":1764414118637,"user":{"displayName":"–î–º–∏—Ç—Ä–∏–π –ü–µ—Ç—Ä–æ–≤","userId":"07403972255786892434"},"user_tz":-180},"id":"OfIXXvst4y0z","outputId":"04476411-ad72-428a-f066-83986fe08b41"},"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabulary length: 87012\n"]}],"execution_count":19},{"cell_type":"code","source":"word2ind = {char: i for i, char in enumerate(vocab)}\nind2word = {i: char for char, i in word2ind.items()}","metadata":{"id":"NBOZy_Mb64Un","executionInfo":{"status":"ok","timestamp":1764414118641,"user_tz":-180,"elapsed":6,"user":{"displayName":"–î–º–∏—Ç—Ä–∏–π –ü–µ—Ç—Ä–æ–≤","userId":"07403972255786892434"}}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"class CustomDataset:\n    def __init__(self, sentences):\n        self.data = sentences\n        self.unk_id = word2ind['<unk>']\n        self.bos_id = word2ind['<bos>']\n        self.eos_id = word2ind['<eos>']\n        self.pad_id = word2ind['<pad>']\n\n    def __getitem__(self, idx):\n        processed_text = tokenizer.tokenize(self.data[idx][1])\n        source = self.data[idx][2]\n\n        tokenized_sentence = [self.bos_id]\n        tokenized_sentence += [\n            word2ind.get(word, self.unk_id) for word in processed_text\n        ]\n        tokenized_sentence += [self.eos_id]\n\n        train_sample = {\n            \"text\": tokenized_sentence,\n            \"source\": source,\n            \"label\": self.data[idx][3]\n        }\n\n        return train_sample\n\n    def __len__(self) -> int:\n        return len(self.data)\n\n\ndef collate_fn_with_padding(input_batch, pad_id=word2ind['<pad>'], max_len=256):\n    seq_lens = [len(x['text']) for x in input_batch]\n    max_seq_len = min(max(seq_lens), max_len)\n\n    new_batch = []\n    for sequence in input_batch:\n        sequence['text'] = sequence['text'][:max_seq_len]\n        for _ in range(max_seq_len - len(sequence['text'])):\n            sequence['text'].append(pad_id)\n\n        new_batch.append(sequence['text'])\n\n    sequences = torch.LongTensor(new_batch).to(device)\n    labels = torch.LongTensor([x['label'] for x in input_batch]).to(device)\n\n    new_batch = {\n        'input_ids': sequences,\n        'label': labels\n    }\n\n    return new_batch","metadata":{"id":"g4B9yuiZyEmv","executionInfo":{"status":"ok","timestamp":1764414118667,"user_tz":-180,"elapsed":16,"user":{"displayName":"–î–º–∏—Ç—Ä–∏–π –ü–µ—Ç—Ä–æ–≤","userId":"07403972255786892434"}}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"X_train, X_val = train_test_split(train_data, test_size=0.1, shuffle=False)\n\ntrain_dataset = CustomDataset(X_train)\nval_dataset = CustomDataset(X_val)\n\nbatch_size = 25\ntrain_dataloader = DataLoader(\n    train_dataset, shuffle=True, collate_fn=collate_fn_with_padding, batch_size=batch_size)\n\nval_dataloader = DataLoader(\n    val_dataset, shuffle=False, collate_fn=collate_fn_with_padding, batch_size=batch_size)","metadata":{"id":"RZNW_UH3yThN","executionInfo":{"status":"ok","timestamp":1764414118688,"user_tz":-180,"elapsed":19,"user":{"displayName":"–î–º–∏—Ç—Ä–∏–π –ü–µ—Ç—Ä–æ–≤","userId":"07403972255786892434"}}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"def F1macro(model, val_dataloader) -> float:\n    predictions = []\n    target = []\n    model.eval()\n\n    with torch.no_grad():\n        for batch in val_dataloader:\n            logits = model(batch['input_ids'].to(device))\n            predictions.append(logits.argmax(dim=1))\n            target.append(batch['label'].to(device))\n\n    predictions = torch.cat(predictions).cpu().numpy()\n    target = torch.cat(target).cpu().numpy()\n\n    macro_f1 = f1_score(predictions, target, average='macro')\n\n    return macro_f1\n\ndef accuracy(model, val_dataloader):\n    predictions = []\n    target = []\n    model.eval()\n\n    with torch.no_grad():\n        for batch in val_dataloader:\n            logits = model(batch['input_ids'].to(device))\n            predictions.append(logits.argmax(dim=1))\n            target.append(batch['label'].to(device))\n\n    predictions = torch.cat(predictions).cpu().numpy()\n    target = torch.cat(target).cpu().numpy()\n\n    macro_f1 = f1_score(predictions, target, average='macro')\n\n    return macro_f1","metadata":{"id":"RWKCFddw872I","executionInfo":{"status":"ok","timestamp":1764414125232,"user_tz":-180,"elapsed":4,"user":{"displayName":"–î–º–∏—Ç—Ä–∏–π –ü–µ—Ç—Ä–æ–≤","userId":"07403972255786892434"}}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"class BaseModel(nn.Module):\n    def __init__(\n        self, hidden_dim, vocab_size, num_classes,\n        aggregation_type: str = 'max', lstm_layers: int = 1\n        ):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, hidden_dim)\n        self.gru = nn.LSTM(hidden_dim, hidden_dim, num_layers=lstm_layers, bidirectional=True)\n        self.linear = nn.Linear(hidden_dim * 2 * 2, hidden_dim)\n        self.projection = nn.Linear(hidden_dim, num_classes)\n\n        self.non_lin = nn.Tanh()\n        self.dropout = nn.Dropout(p=0.3)\n\n        self.aggregation_type = aggregation_type\n\n    def forward(self, input_batch) -> torch.Tensor:\n        embeddings = self.embedding(input_batch)\n        output, _–í–µ = self.gru(embeddings)\n\n        if self.aggregation_type == 'max':\n            output = output.max(dim=1)[0]\n        elif self.aggregation_type == 'mean':\n            output = output.mean(dim=1)\n        elif self.aggregation_type == 'max+mean':\n            max_pool = output.max(dim=1)[0]\n            mean_pool = output.mean(dim=1)\n\n            output = torch.cat([max_pool, mean_pool], dim=1)\n        else:\n            raise ValueError(\"Invalid aggregation_type\")\n\n        output = self.dropout(self.linear(self.non_lin(output)))\n        prediction = self.projection(self.non_lin(output))\n\n        return prediction","metadata":{"id":"93ETyI40KyeL","executionInfo":{"status":"ok","timestamp":1764414126767,"user_tz":-180,"elapsed":21,"user":{"displayName":"–î–º–∏—Ç—Ä–∏–π –ü–µ—Ç—Ä–æ–≤","userId":"07403972255786892434"}}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"def train(model, optimizer, epochs, criterion, train_loader, val_loader):\n    train_losses = []\n    val_losses = []\n\n    model = model.to(device)\n\n    for epoch in range(epochs):\n        model.train()\n        train_losses_per_epoch = []\n        val_losses_per_epoch = []\n\n        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n\n        for batch in pbar:\n            optimizer.zero_grad()\n\n            logits = model(batch['input_ids'].to(device))\n            loss = criterion(logits, batch['label'])\n\n            loss.backward()\n            optimizer.step()\n            train_losses_per_epoch.append(loss.item())\n\n        train_losses.append(np.mean(train_losses_per_epoch))\n\n        with torch.no_grad():\n            model.eval()\n            for batch in val_loader:\n                logits = model(batch['input_ids'].to(device))\n                loss = criterion(logits, batch['label'])\n\n                val_losses_per_epoch.append(loss.item())\n\n        val_losses.append(np.mean(val_losses_per_epoch))\n\n        print(f\"Epoch {epoch+1}/{epochs} | \"\n              f\"train_loss={train_losses[-1]:.2f} | \"\n              f\"val_loss={val_losses[-1]:.2f} |\"\n              f\"F1-micro={F1macro(model, val_dataloader)}\")\n\n    return train_losses, val_losses","metadata":{"id":"32YUK_4rKIPO","executionInfo":{"status":"ok","timestamp":1764414129948,"user_tz":-180,"elapsed":26,"user":{"displayName":"–î–º–∏—Ç—Ä–∏–π –ü–µ—Ç—Ä–æ–≤","userId":"07403972255786892434"}}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"model = BaseModel(\n    hidden_dim=256,\n    vocab_size=len(vocab),\n    num_classes=3,\n    lstm_layers=2,\n    aggregation_type='max+mean'\n    ).to(device)\ncriterion = nn.CrossEntropyLoss()","metadata":{"id":"_6KzJ33cLpJ3","executionInfo":{"status":"ok","timestamp":1764414132526,"user_tz":-180,"elapsed":208,"user":{"displayName":"–î–º–∏—Ç—Ä–∏–π –ü–µ—Ç—Ä–æ–≤","userId":"07403972255786892434"}}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\nepochs = 4\n\ntrain_losses, val_losses = train(model, optimizer, epochs, criterion, train_dataloader, val_dataloader)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":496,"referenced_widgets":["b953d757480041909bd66a0f04d8ca25","2577e7494d1a4c8d8ba4c09ee6259eda","d68c14c337984ba79a4413e800ad842c","2a18a70434ca45d295de27f715b28cb2","df6aa764480048449a3bf9960cbec9b6","a26053054d424f25a48fc60bbff76f71","1b9fbcdb017b4136a7df52aa1c6afebc","b64f1a4864fc439699986911911940c0","601e2d75904e45a69820dff30d333f01","477159f874d5433da593b7aa7e620eb8","bb585f852fc1402792a88cbeaa3ae71f","13b9cf4d9cc64747be0865885d932ec8","f21a9d1849ff491f8bb09a36ff026242","2761b478036c4be7899ddd5150de85a6","f06c0dcce50f4a9f93178ca3afe74ca7","1ecac6921562442597aacd876c4b3a51","1d09fba8345f4b05a30bfa7b73f2a1f7","eaeda769480c4342935664c6900294ea","3b68da0cfced47febd6650ae9f348b74","dba3e15f128d4926928d241f7e9511a5","5c612edb59b74a7ab49f9430cf69dbb3","b46a61bdf9cd40368b947c0957f39264"]},"id":"B9YhupRDLLwp","outputId":"7af2a8f8-44a4-444f-d8c0-4c74714a80bc","executionInfo":{"status":"error","timestamp":1764414617862,"user_tz":-180,"elapsed":484740,"user":{"displayName":"–î–º–∏—Ç—Ä–∏–π –ü–µ—Ç—Ä–æ–≤","userId":"07403972255786892434"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["Epoch 1/4:   0%|          | 0/8366 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b953d757480041909bd66a0f04d8ca25"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch 1/4 | train_loss=0.83 | val_loss=0.74 |F1-micro=0.66249975031834\n"]},{"output_type":"display_data","data":{"text/plain":["Epoch 2/4:   0%|          | 0/8366 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13b9cf4d9cc64747be0865885d932ec8"}},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-752545540.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipython-input-1265870581.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, epochs, criterion, train_loader, val_loader)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-1167713650.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_batch)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_–í–µ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregation_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'max'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1127\u001b[0;31m             result = _VF.lstm(\n\u001b[0m\u001b[1;32m   1128\u001b[0m                 \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m                 \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"execution_count":31},{"cell_type":"code","source":"plt.figure(figsize=(3, 2))\nplt.plot(np.arange(len(train_losses)), train_losses, label='Train', color='blue')\nplt.plot(np.arange(len(val_losses)), val_losses, label='Validation', color='orange')\n\nplt.xlabel('Epoch')\nplt.title('MSE loss')\nplt.legend()\nplt.show()\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":311},"executionInfo":{"elapsed":17,"status":"error","timestamp":1764414619622,"user":{"displayName":"–î–º–∏—Ç—Ä–∏–π –ü–µ—Ç—Ä–æ–≤","userId":"07403972255786892434"},"user_tz":-180},"id":"Cy5ooHMOMRv5","outputId":"141404ee-5734-4198-945b-2f6e7e3710ca"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'train_losses' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3536858306.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'orange'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_losses' is not defined"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 300x200 with 0 Axes>"]},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"save_data = [model, word2ind]\n\nwith open(\"save_data.pkl\", \"wb\") as f:\n  pickle.dump(save_data, f)","metadata":{"id":"mckL8Is1uzc-","executionInfo":{"status":"ok","timestamp":1764414621545,"user_tz":-180,"elapsed":529,"user":{"displayName":"–î–º–∏—Ç—Ä–∏–π –ü–µ—Ç—Ä–æ–≤","userId":"07403972255786892434"}}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"!git clone https://dmiptrv0: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@github.com/mirkuriit/hack-change-2025.git\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NtyurcV3T0Nk","executionInfo":{"status":"ok","timestamp":1764414672281,"user_tz":-180,"elapsed":1255,"user":{"displayName":"–î–º–∏—Ç—Ä–∏–π –ü–µ—Ç—Ä–æ–≤","userId":"07403972255786892434"}},"outputId":"68a97fe4-0871-4219-d6ef-167d77095830"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'hack-change-2025'...\n","remote: Enumerating objects: 78, done.\u001b[K\n","remote: Counting objects: 100% (78/78), done.\u001b[K\n","remote: Compressing objects: 100% (55/55), done.\u001b[K\n","remote: Total 78 (delta 19), reused 73 (delta 14), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (78/78), 59.08 KiB | 889.00 KiB/s, done.\n","Resolving deltas: 100% (19/19), done.\n"]}],"execution_count":35},{"cell_type":"code","source":"import os\n!git push origin HEAD\nos.chdir(\"hack-change-2025\")","metadata":{"id":"IPdYrReLT25v","executionInfo":{"status":"ok","timestamp":1764414682405,"user_tz":-180,"elapsed":3,"user":{"displayName":"–î–º–∏—Ç—Ä–∏–π –ü–µ—Ç—Ä–æ–≤","userId":"07403972255786892434"}}},"outputs":[],"execution_count":36}]}